---
title: "Exploratory Analyses"
author: "Ashley L. Miller"
date: "5/20/2019"
output: html_document
---

```{r setup, include = FALSE}
# load required packaages
library(sundry)
library("papaja") # for creating the apa journal article
library(tidyverse) # for purrr, dplyr, and ggplot2 functions
library(rio) # for easy imporrting of data
library(here) # for reproducible paths
library(magrittr) # for the compound assigiment pipe-operator
library(lme4) # for conducting linear mixed-effects models
library(lmerTest) # for calculating t-tests for linear mixed-effects models
library(psych) # for caculating cronbach's alpha

# import data as tibble and clean column names
data1 <- rio::import(here::here("data", "data_1.xlsx"), setclass = "tibble") %>%
  janitor::clean_names()

# turn off scientific notation
options(scipen = 999)
```

```{r data1_rename, include = FALSE}
# drop the display order columns and the custom demographic columns
data1 %<>%
  select(-contains("do"),
         -contains("text"))

# manualy rename the demographic columns
data1 %<>%
  rename(age          = q1_1,
         gender       = q1_2,
         race         = q1_4)


# create vectors of subscale names
dd_subs  <- c("mach", "narc", "psyc") # subscales for the dirty dozen scale

sns_subs <- c("facebook", # subscales for the frequency and length of sns use 
              "pinterest", 
              "instagram", 
              "linkedin", 
              "twitter", 
              "snapchat", 
              "youtube", 
              "whatsapp", 
              "reddit", 
              "4chan", 
              "tumblr")

con_subs <- c("society", # subscales for questions assessing benefit of sns
              "self")
 
mot_subs <- c("inform", # subscales for the motivations to use the internet 
              "interp", # scale
              "entert")
 
add_subs <- c("salience", # susbscales for the internet addiction scale
              "tolerance",
              "mood",
              "relapse",
              "withdraw",
              "conflict")

# create a tibble containing all the necessary information for renaming the 
# columns
data_rename <- tibble(
                      # the scale names
                      scale_names = c("dd", 
                                      "freq",
                                      "len",
                                      "sns_perc",
                                      "int_mot",
                                      "int_addict"),
                      # the scale subscales created above
                      sub_names   = list(dd_subs,
                                         sns_subs,
                                         sns_subs,
                                         con_subs,
                                         mot_subs,
                                         add_subs),
                      # the total length of the scales
                      scale_lens  = c(12, 11, 11, 2, 20, 18),
                      # the length of the subscales (only one value if all are 
                      # the same length)
                      sub_lens    = list(4, 1, 1, 1, c(8, 7, 5), 3))

# create a function for detecting columns names from a string
col_find <- function(pattern, data) {
  
  # ensure pattern is a character and the data is a dataframe
  if (!is.character(pattern)) {
    stop("Pattern must be of type character.")
  } else if (!is.data.frame(data)) {
    stop("Data must of type dataframe/tibble.")
  }
  
  # return column names that contain the pattern
  grepl(pattern, names(data))
}

# create a function for creating column names using the data_rename tibble
name_creator <- function(scale_name, sub_name, scale_len, sub_len) {
  
  # calculate the subscale length if no subscale length provided
  if (missing(sub_len)) {
    sub_len <- scale_len / length(sub_name)
  }
  
  # create a vector of subscale names to match length of the scale. `times` has 
  # to be used instead of `each` when subscales of different lengths are 
  # specified
  if (length(sub_len) == 1) {
    sub_vector <- rep(sub_name, each = sub_len)
  } else {
    sub_vector <- rep(sub_name, times = sub_len) 
  }

  # combine the scale names with the sub_scale names
  var_names <- paste(scale_name, sub_vector, sep = "_")
  
  # if length of the subscale is not equal to one, add an item identifier to the
  # column names (this segment, in particular, should be refactored)
  if (any(sub_len != 1)) {
    # get a sequence from 1 the length of a subscale for each subscale
    item_nums <- flatten_dbl(map(sub_len, seq_len))
    # repeat the sequence the number of subscales there are
    item_nums <- rep(item_nums, times = scale_len / sum(sub_len))
    # combine the variable names with the item numbers
    var_names <- paste(var_names, item_nums, sep = "_")
  }
  
  # return scale_sub
  var_names
  
}

# iterate through the data_rename tibble and create a list of column names
col_names <- pmap(list(data_rename$scale_names,
                       data_rename$sub_names,
                       data_rename$scale_lens,
                       data_rename$sub_lens),
                  ~name_creator(..1, ..2, ..3, ..4)
)

# assign created column names to data1
names(data1)[col_find("q7", data1)] <- unlist(col_names)

# remove uneeded variables
rm(list = setdiff(ls(), c("data1", "col_names", "col_find")))
```

```{r data1_convert_to_long, include = FALSE}
# add an id column to the data
data1 %<>%
  mutate(id = 1:n()) %>%
  select(id, everything())

# transform the data to long format with respect the the frequency of sns use 
# and the length of sns use
data1 %<>%
  # over gather all frequency and length columns
  gather("key", "value", freq_facebook:len_tumblr) %>%
  # separate the key columns into a column specifying freq/length and a column
  # specifying the social media site
  separate(key, into = c("variable", "sns"), sep = "_") %>%
  # spread the frequency and length column into two separate columns
  spread(variable, value)

# transform the data to long format with respect to perception of sns
data1 %<>%
  # gather the two columns (i.e., benefit of sns to the self and benefit of sns
  # to society)
  gather("sns_perc_context", "sns_perc_rating", starts_with("sns_perc")) %>%
  # drop all text before "self" or "society
  mutate(sns_perc_context = gsub(".*_", "", sns_perc_context))

```

```{r data1_parse_length, include = FALSE}
# identify the units responses were given in (even though I requested answers in 
# minutes)
data1 %<>%
  mutate(len_unit  = case_when(grepl("(hour|hr)", len) ~ 60,
                               TRUE                    ~ 1))

# create a function for calculating the mean of time responses given as a 
# character ranges. Example: "like 3-5 hours a day" would become "4"
range_mean <- function(x) {
  # attempt to find a mean for only those with a hyphen in the response
  if (grepl("-", x)) {
    # extract the range from the response
    x <- str_extract(x, "\\d*-\\d*")
    # split the string around the dash
    x <- strsplit(x, "-")[[1]]
    # convert the string to numeric and calculate the mean
    x <- mean(as.numeric(x))
    # maintaining the original type, convert the result back to a character
    as.character(x)
  } else {
    # if no hyphen, return x
    x
  }
}


# replace all range responses with the means of those ranges
data1$len <- map_chr(data1$len, range_mean)

# parse the numbers
data1 %<>%
  mutate(# replace written numbers with arabic numerals
         len = case_when(len == "ten"                  ~ "10",
                         len == "3o"                   ~ "30",
                         len == "sixty"                ~ "60",
                         len == "eighty"               ~ "80",
                         grepl("(zero|no|never)", len) ~ "0",
                         TRUE                          ~ len),
         # parse the numbers
         len = parse_number(len),
         # calculate the length in minutes
         len = len * len_unit) %>%
         # drop the unit column
         select(-len_unit)
```

```{r data1_format, include = FALSE}
# factorize and label factors
data1 %<>%
  mutate(# factorize gender and apply labels
        gender           = factor(gender, labels = c("Male",
                                                     "Female",
                                                     "Non-binary",
                                                     "Prefer not to say",
                                                     "Other")),
        # factorize race and apply labels
        race             = factor(race, labels   = c("American Indian or Alaska Native",
                                                     "Asian",
                                                     "Black or African American",
                                                     "Native Hawaiian or Other Pacific Islander",
                                                     "Caucasian",
                                                     "Hispanic, Latinx, or Spanish Origin",
                                                     "Middle Eastern or North African",
                                                     "I prefer not to answer",
                                                     "Some other ethnicity or origin")),
        # factorize social media site
        sns              = factor(sns),
        # factorize context
        sns_perc_context = factor(sns_perc_context),
        # numerize frequency
        freq             = as.numeric(freq))

```

```{r data1_composites, include = FALSE}
# drop column names not to be made into composites
comp_names <- col_names[-2:-4]

# drop item identifiers to create the composite names; retain only unique names
comp_names %<>%
  map(str_replace, "_\\d", "") %>%
  map(unique)

# create a function for calculating alpha given a string pattern
str_alpha <- function(pattern, data) {
  # find names of columns that match the string
  cols_found  <- col_find(pattern, data)
  # extract only those columns from the data 
  data <- data[, cols_found]
  # calculate and extract the alpha value
  alpha(data)[["total"]][["raw_alpha"]]
}

# calculate alphas for the composites
alphas <- comp_names %>%
  map(map_dbl, str_alpha, data1) %>%
  flatten_dbl() 

# name the alpha composites
names(alphas) <- flatten_chr(comp_names)

# create the str_message function for double-checking one's work
str_message <- function(data) {
  names_len <- length(names(data))
  if (names_len <= 4) {
    col_names <- paste(names(data), collapse = ", ")
  } else {
    col_names <- paste0(paste(names(data)[1:3], collapse = ", "), ", and ", names_len - 3, " more")
  }
  message(paste0("Row means were calculated using ", 
                ncol(data), 
                " columns: ",
                col_names,
                "."))
}

# create a function for calculating rowmeans given a string pattern
str_means <- function(pattern, data) {
  # find names of columns that match the string
  cols_found  <- col_find(pattern, data)
  # extract only those columns from the data 
  data <- data[, cols_found]
  # message user how the composites were created
  str_message(data)
  # calculate row means
  rowMeans(data)
}

# create composites
data_comp <- comp_names %>%
  map(map, str_means, data1) %>%
  flatten_dfc()

# assign names to the created composites
names(data_comp) <- paste0(flatten_chr(comp_names), "_comp")

# combine the composites with the existing dataframe
data1 <- data1 %>%
  cbind(data_comp)

# drop unneeded, single item columns (ACTUALLY, we'll need these for checking SDs)
#data1 %<>%
#  select(-matches("\\d$"))

# clean up the environment
rm(list = setdiff(ls(), c("data1", "alphas", "col_find")))
```

Sagacious intro text goes here.

# Method

## Participants

## Material and procedure

# Results

```{r tidy_data}

genderxsns_data <- data1 %>%
  select(id, age, gender, race, sns:sns_perc_rating, contains("comp")) %>%
  filter(gender == "Male" | gender == "Female") %>%
  filter(sns != "4chan" &
         sns != "linkedin" &
         sns != "pinterest" &
         sns != "tumblr" &
         sns != "whatsapp") %>%
  arrange(id)

ash_data <- data1 %>%
  select(id, age, gender, race, sns:sns_perc_rating, contains("comp")) %>%
  filter(gender == "Male" | gender == "Female") %>%
  arrange(id)

ash_data %<>%
  mutate(mach_group = case_when(dd_mach_comp > quantile(dd_mach_comp, .75, 
                                                        na.rm = TRUE) ~ "High",
                                dd_mach_comp < quantile(dd_mach_comp, .25, 
                                                        na.rm = TRUE) ~ "Low",
                                TRUE ~ "Mid"),
         mach_group = factor(mach_group, levels = c("Low", "Mid", "High")))

ash_data %<>%
  mutate(narc_group = case_when(dd_narc_comp > quantile(dd_narc_comp, .75, 
                                                        na.rm = TRUE) ~ "High",
                                dd_narc_comp < quantile(dd_narc_comp, .25, 
                                                        na.rm = TRUE) ~ "Low",
                                TRUE ~ "Mid"),
         narc_group = factor(narc_group, levels = c("Low", "Mid", "High")))

ash_data %<>%
  mutate(psyc_group = case_when(dd_psyc_comp > quantile(dd_psyc_comp, .75, 
                                                        na.rm = TRUE) ~ "High",
                                dd_psyc_comp < quantile(dd_psyc_comp, .25, 
                                                        na.rm = TRUE) ~ "Low",
                                TRUE ~ "Mid"),
         psyc_group = factor(psyc_group, levels = c("Low", "Mid", "High")))

corr_data <- ash_data %>% 
  spread(sns_perc_context, sns_perc_rating) %>%
  group_by(id) %>%
  mutate(mean_freq = mean(freq, na.rm = TRUE),
         sum_freq = sum(freq, na.rm = TRUE),
         sum_len = sum(len, na.rm = TRUE)) %>%
  select(id, gender, mean_freq, sum_freq, sum_len, self, society, dd_mach_comp,
         dd_narc_comp, dd_psyc_comp, int_mot_entert_comp, int_mot_inform_comp,
         int_mot_interp_comp, contains("addict"), contains("group")) %>%
  unique()

export(corr_data, here("data", "test.sav"))

corr_data <- rio::import(here::here("data", "test.sav"), 
                         setclass = "tibble") %>%
  filter(outlier == 0.00)

```

```{r plots}

ggplot(corr_data, aes(x = dd_narc_comp, y = int_addict_salience_comp)) +
  geom_smooth(method = "lm") +
  theme_bw(base_size = 14) +
  theme(axis.title = element_text(face = "bold"),
        strip.text = element_text(face = "bold", size = 14),
        legend.title = element_text(face = "bold"),
        panel.grid.major = element_line(colour = "white"), 
        panel.grid.minor = element_line(colour = "white")) +
    scale_x_continuous(breaks = c(1, 2, 3, 4, 5),
                       labels = c("1", "2", "3", "4", "5"),
                       limits = c(1, 5)) +
    labs(y = "Social Media Addiction Salience",
         x = "Narcissism")
  
ggplot(corr_data, aes(x = dd_narc_comp, y = int_addict_tolerance_comp)) +
  geom_smooth(method = "lm") +
  theme_bw(base_size = 14) +
  theme(axis.title = element_text(face = "bold"),
        strip.text = element_text(face = "bold", size = 14),
        legend.title = element_text(face = "bold"),
        panel.grid.major = element_line(colour = "white"), 
        panel.grid.minor = element_line(colour = "white")) +
    scale_x_continuous(breaks = c(1, 2, 3, 4),
                       labels = c("1", "2", "3", "4"),
                       limits = c(1, NA)) +
    labs(y = "Social Media Addiction Tolerance",
         x = "Narcissism")

```

```{r perception analyses}

ash_data %<>%
 filter(!is.na(sns),
        !is.na(int_mot_inform_comp),
        !is.na(int_mot_interp_comp),
        !is.na(int_mot_entert_comp))


model0            <- lmer(len ~ (1 | id), data = ash_data)
model0_sns        <- lmer(len ~ sns + (1 | id), data = ash_data)


#####################################################################################
###### Examining potential influence of using social media use for information ###### 
#####################################################################################

model0_sns_inform <- lmer(len ~ sns + int_mot_inform_comp + 
                         (1 | id), 
                         data = ash_data)
model0_snsxinfom <- lmer(len ~ sns*int_mot_inform_comp + 
                         (1 | id), 
                         data = ash_data)

anova(model0, model0_sns, model0_sns_inform, model0_snsxinfom) #model0_sns is best; drop inform predictor

######################################################################################
###### Examining influence of using social media use for interpersonal relation ###### 
######################################################################################

model0_sns_interp <- lmer(len ~ sns + int_mot_interp_comp + 
                         (1 | id), 
                         data = ash_data)
model0_snsxinterp <- lmer(len ~ sns*int_mot_interp_comp*gender + 
                         (1 | id), 
                         data = ash_data)

anova(model0_sns, model0_sns_interp, model0_snsxinterp) 
#both interp models are better than sns only model
# best model contains interaction
summary(model0_snsxinterp)

ash_data %>%
  filter(sns != "4chan") %>%
  group_by(sns) %>%
  summarize(len_m  = mean(len, na.rm = TRUE),
            len_se = sundry::se(len),
            interp_m = mean(int_mot_interp_comp, na.rm = TRUE),
            interp_se = sundry::se(int_mot_interp_comp)) %>%
  ggplot(aes(x = interp_m, y = len_m, fill = sns)) +
    geom_col(position = "dodge", alpha = 0.9) +
    scale_fill_viridis_d(name = "Social Media Site") +
    theme_bw(base_size = 14) +
    theme(axis.title = element_text(face = "bold"),
          strip.text = element_text(face = "bold", size = 14),
          legend.title = element_text(face = "bold"),
          panel.grid.major = element_line(colour = "white"), 
          panel.grid.minor = element_line(colour = "white")) +
    labs(y = "Average time spent on Social \nMedia Sites per Day (minutes)",
         x = "Interpersonal Motivation")

#############################################################################
###### Examining influence of using social media use for entertainment ###### 
#############################################################################

model0_sns_entert <- lmer(len ~ sns + int_mot_entert_comp + 
                         (1 | id), 
                         data = ash_data)
model0_snsxentert <- lmer(len ~ sns*int_mot_entert_comp + 
                         (1 | id), 
                         data = ash_data)
anova(model0_sns, model0_sns_entert, model0_snsxentert)
#both entert models are better than sns only model
# best model contains interaction
summary(model0_snsxentert)

model1 <- lmer(len ~ sns*int_mot_interp_comp + 
                     sns*int_mot_entert_comp + 
              (1 | id), 
              data = ash_data)
anova(model0_snsxentert, model1) #model 1 best
anova(model0_snsxinterp, model1) #model 1 is marginally better (p = .07)

summary(model1)

#Basically, people who rely more on social media for interpesonal communication spend more time on snapchat each day
#Similarly, people who rely more on social media for entertainment spend more time on youtube each day
#People who rely more on social media for entertainment spend marginally more time on reddit each day

```

```{r genderxperception}

genderxsns_data %<>%
 filter(!is.na(sns),
        !is.na(int_mot_inform_comp),
        !is.na(int_mot_interp_comp),
        !is.na(int_mot_entert_comp),
        !is.na(gender))

model1 <- lmer(len ~ sns*int_mot_interp_comp + 
                     sns*int_mot_entert_comp + 
              (1 | id), 
              data = genderxsns_data)

gender_interp_entert <- lmer(len ~ sns*int_mot_interp_comp*gender + 
                                   sns*int_mot_entert_comp*gender +
                     (1 | id), 
                     data = genderxsns_data)
anova(model1, gender_interp_entert)
summary(gender_interp_entert) #fits data best

```

```{r mach_addiction}
#Examining whether mood mofication/time on social media relation varies as a funciton of Machiavellianism
corr_data %>%
  mutate(mach_group = as.factor(mach_group)) %>%
  filter(mach_group != "Mid") %>%
  ggplot(aes(x = int_addict_mood_comp, y = sum_len, 
             group = mach_group, colour = mach_group)) +
      geom_smooth(method = "lm", 
                  se = FALSE,
                  size = 2) +
      theme_bw(base_size = 14) +
      scale_color_manual(values = c("#4A235A", "#D2B4DE")) +
      theme(axis.title = element_text(face = "bold"),
            strip.text = element_text(face = "bold", size = 14),
            legend.title = element_text(face = "bold")) +
        labs(y = "Total Time Spent on Social \nMedia Sites per Day (minutes)",
             x = "Social Media Addiction Mood Modification",
             colour = "Machiavellianism")

#Examining whether addicition salience/time on social media relation varies as a funciton of Machiavellianism
corr_data %>%
  mutate(mach_group = as.factor(mach_group)) %>%
  filter(mach_group != "Mid") %>%
  ggplot(aes(x = int_addict_salience_comp, y = sum_len, 
             group = mach_group, colour = mach_group)) +
      geom_smooth(method = "lm", 
                  se = FALSE,
                  size = 2) +
      theme_bw(base_size = 14) +
      scale_color_manual(values = c("#4A235A", "#D2B4DE")) +
      theme(axis.title = element_text(face = "bold"),
            strip.text = element_text(face = "bold", size = 14),
            legend.title = element_text(face = "bold")) +
        labs(y = "Total Time Spent on Social \nMedia Sites per Day (minutes)",
             x = "Social Media Addiction Salience",
             colour = "Machiavellianism")

```

```{r narc_addiction}
#Examining whether mood modification/time on social media relation varies as a funciton of Narcissism
corr_data %>%
  mutate(narc_group = as.factor(narc_group)) %>%
  filter(narc_group != "Mid") %>%
  ggplot(aes(x = int_addict_mood_comp, y = sum_len, 
             group = narc_group, colour = narc_group)) +
      geom_smooth(method = "lm", 
                  se = FALSE,
                  size = 2) +
      theme_bw(base_size = 14) +
      scale_color_manual(values = c("#17737B", "#5FCDD6")) +
      theme(axis.title = element_text(face = "bold"),
            strip.text = element_text(face = "bold", size = 14),
            legend.title = element_text(face = "bold")) +
      labs(y = "Total Time Spent on Social \nMedia Sites per Day (minutes)",
             x = "Social Media Addiction Mood Modification",
             colour = "Narcissism")

#Examining whether addicition salience/time on social media relation varies as a funciton of Narcissism
corr_data %>%
  mutate(narc_group = as.factor(narc_group)) %>%
  filter(narc_group != "Mid") %>%
  ggplot(aes(x = int_addict_salience_comp, y = sum_len, group = narc_group, colour = narc_group)) +
      geom_smooth(method = "lm", 
                  se = FALSE,
                  size = 2) +
      theme_bw(base_size = 14) +
      scale_color_manual(values = c("#17737B", "#5FCDD6")) +
      theme(axis.title = element_text(face = "bold"),
            strip.text = element_text(face = "bold", size = 14),
            legend.title = element_text(face = "bold"),
            panel.grid.major = element_line(colour = "white"), 
            panel.grid.minor = element_line(colour = "white")) +
        labs(y = "Total Time Spent on Social \nMedia Sites per Day (minutes)",
             x = "Social Media Addiction Salience",
             colour = "Narcissism")

#Examining whether addicition tolerance/time on social media relation varies as a funciton of Narcissism
corr_data %>%
  mutate(narc_group = as.factor(narc_group)) %>%
  filter(narc_group != "Mid") %>%
  ggplot(aes(x = int_addict_tolerance_comp, y = sum_len, 
             group = narc_group, colour = narc_group)) +
      geom_smooth(method = "lm", 
                  se = FALSE,
                  size = 2) +
      theme_bw(base_size = 14) +
      scale_color_manual(values = c("#17737B", "#5FCDD6")) +
      theme(axis.title = element_text(face = "bold"),
            strip.text = element_text(face = "bold", size = 14),
            legend.title = element_text(face = "bold")) +
        labs(y = "Total Time Spent on Social \nMedia Sites per Day (minutes)",
             x = "Social Media Addiction Tolerance",
             colour = "Narcissism")
```


