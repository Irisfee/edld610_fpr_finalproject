---
title             : "Clickbait Title with SEO Keywords"
shorttitle        : "Clickbait Title"

author: 
  - name          : "Cameron S. Kay"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Department of Psychology, 1227 University of Oregon, Eugene, OR 97403"
    email         : "ckay@uoregon.edu"
  - name          : "Ashley L. Miller"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "University of Oregon"

authornote: |
  Cameron Stuart Kay, Department of Psychology, University of Oregon; Ashley L. Miller, Department of Psychology, University of Oregon.

abstract: |
 Abstract goes herey
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["r-references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no

header-includes:
  - \raggedbottom
  - \setlength{\parskip}{0pt}

documentclass     : "apa6"
classoption       : "man, fleqn, noextraspace"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
# install packages if you do not have them installed already
# devtools::install_github("datalorax/sundry")
# install.packages("papaja")
# install.packages("tidyverse")
# install.packages("rio")
# install.packages("here")
# install.packages("magrittr")
# install.packages("lme4")
# install.packages("lmerTest")
# install.packages("psych")
# install.packages("glue")

# load packages
library(sundry) # for calculating standard errors
library("papaja") # for creating the apa journal article
library(tidyverse) # for purrr, dplyr, and ggplot2 functions
library(rio) # for easy imporrting of data
library(here) # for reproducible paths
library(magrittr) # for the compound assigiment pipe-operator
library(lme4) # for conducting linear mixed-effects models
library(lmerTest) # for calculating t-tests for linear mixed-effects models
library(psych) # for caculating cronbach's alpha
library(glue) # for parallel iteration 

# source custom functions (the rmarkdown document is unwieldy otherwise)
source(here("functions", "str_cols_find.R")) # CUSTOM FUNCTION 1: for extracting
                                             # columns from a dataframe using a 
                                             # string
source(here("functions", "name_creator.R"))  # CUSTOM FUNCTION 2: for creating
                                             # variable names given strings
source(here("functions", "range_mean.R"))    # CUSTOM FUNCTION 3: create a 
                                             # function for calculating the mean 
                                             # of a time response given as a 
                                             # character range. Example: "like 
                                             # 3-5 hours a day" would become "4"
source(here("functions", "str_alpha.R"))     # CUSTOM FUNCTION 4: for 
                                             # calculating cronbach's alpha for
                                             # columns that match a string
source(here("functions", "str_composite.R")) # CUSTOM FUNCTION 5: for 
                                             # calculating rowmeans for
                                             # columns that match a string
source(here("functions", "str_composite.R")) # CUSTOM FUNCTION 6: for rounding 
                                             # and formatting for printing in 
                                             # one step

# create a vector of the custom functions
custom_functions <- objects()

# import data as tibble and clean column names
data1 <- rio::import(here::here("data", "data_1.xlsx"), setclass = "tibble") %>%
  janitor::clean_names()

# turn off scientific notation
options(scipen = 999)
```

```{r data1_rename, include = FALSE}
# drop the display order columns and the custom demographic columns
data1 %<>%
  select(-contains("do"),
         -contains("text"))

# manualy rename the demographic columns
data1 %<>%
  rename(age          = q1_1,
         gender       = q1_2,
         race         = q1_4)


# create vectors of subscale names
dd_subs  <- c("mach", "narc", "psyc") # subscales for the dirty dozen scale

sns_subs <- c("facebook", # subscales for the frequency and length of sns use 
              "pinterest", 
              "instagram", 
              "linkedin", 
              "twitter", 
              "snapchat", 
              "youtube", 
              "whatsapp", 
              "reddit", 
              "4chan", 
              "tumblr")

con_subs <- c("society", # subscales for questions assessing benefit of sns
              "self")
 
mot_subs <- c("inform", # subscales for the motivations to use the internet 
              "interp", # scale
              "entert")
 
add_subs <- c("salience", # susbscales for the internet addiction scale
              "tolerance",
              "mood",
              "relapse",
              "withdraw",
              "conflict")

# create a tibble containing all the necessary information for renaming the 
# columns
data_rename <- tibble(
                      # the scale names
                      scale_names = c("dd", 
                                      "freq",
                                      "len",
                                      "sns_perc",
                                      "int_mot",
                                      "int_addict"),
                      # the scale subscales created above
                      sub_names   = list(dd_subs,
                                         sns_subs,
                                         sns_subs,
                                         con_subs,
                                         mot_subs,
                                         add_subs),
                      # the total length of the scales
                      scale_lens  = c(12, 11, 11, 2, 20, 18),
                      # the length of the subscales (only one value if all are 
                      # the same length)
                      sub_lens    = list(4, 1, 1, 1, c(8, 7, 5), 3))

# iterate through the data_rename tibble and create a list of column names
col_names <- pmap(list(data_rename$scale_names,
                       data_rename$sub_names,
                       data_rename$scale_lens,
                       data_rename$sub_lens),
                  ~name_creator(..1, ..2, ..3, ..4)
)

# assign created column names to data1
names(data1)[str_cols_find("q7", data1)] <- unlist(col_names)

# remove uneeded variables
rm(list = setdiff(ls(), c("data1", "col_names", "custom_functions", custom_functions)))
```

```{r data1_convert_to_long, include = FALSE}
# add an id column to the data
data1 %<>%
  mutate(id = 1:n()) %>%
  select(id, everything())

# transform the data to long format with respect the the frequency of sns use 
# and the length of sns use
data1 %<>%
  # over gather all frequency and length columns
  gather("key", "value", freq_facebook:len_tumblr) %>%
  # separate the key columns into a column specifying freq/length and a column
  # specifying the social media site
  separate(key, into = c("variable", "sns"), sep = "_") %>%
  # spread the frequency and length column into two separate columns
  spread(variable, value)

# transform the data to long format with respect to perception of sns
data1 %<>%
  # gather the two columns (i.e., benefit of sns to the self and benefit of sns
  # to society)
  gather("sns_perc_context", "sns_perc_rating", starts_with("sns_perc")) %>%
  # drop all text before "self" or "society
  mutate(sns_perc_context = gsub(".*_", "", sns_perc_context))

```

```{r data1_parse_length, include = FALSE}
# identify the units responses were given in (even though I specifically 
# requested that the responses be provided in  minutes)
data1 %<>%
  mutate(len_unit  = case_when(grepl("(hour|hr)", len) ~ 60,
                               TRUE                    ~ 1))

#######################################################
#### Variant of purr::map #1 (at least 2 required) ####
#######################################################

# replace all range responses with the means of those ranges
data1$len <- map_chr(data1$len, range_mean)

# parse the numbers
data1 %<>%
  mutate(# replace written numbers with arabic numerals
         len = case_when(len == "ten"                  ~ "10",
                         len == "3o"                   ~ "30",
                         len == "sixty"                ~ "60",
                         len == "eighty"               ~ "80",
                         grepl("(zero|no|never)", len) ~ "0",
                         TRUE                          ~ len),
         # parse the numbers
         len = parse_number(len),
         # calculate the length in minutes by multipling the unit by the length
         len = len * len_unit) %>%
         # drop the unit column
         select(-len_unit)
```

```{r data1_format, include = FALSE}
# factorize and label factors
data1 %<>%
  mutate(# factorize gender and apply labels
        gender           = factor(gender, labels = c("Male",
                                                     "Female",
                                                     "Non-binary",
                                                     "Prefer not to say",
                                                     "Other")),
        # factorize race and apply labels
        race             = factor(race, labels   = c("American Indian or Alaska Native",
                                                     "Asian",
                                                     "Black or African American",
                                                     "Native Hawaiian or Other Pacific Islander",
                                                     "Caucasian",
                                                     "Hispanic, Latinx, or Spanish Origin",
                                                     "Middle Eastern or North African",
                                                     "I prefer not to answer",
                                                     "Some other ethnicity or origin")),
        # factorize social media site
        sns              = factor(sns),
        # factorize context
        sns_perc_context = factor(sns_perc_context),
        # numerize frequency
        freq             = as.numeric(freq))

```

```{r data1_composites, include = FALSE}
# drop column names not to be made into composites
comp_names <- col_names[-2:-4]

#######################################################
#### Variant of purr::map #2 (at least 2 required) ####
#######################################################

# drop item identifiers (e.g., "dd_7") to create the composite names; retain 
# only unique names (e.g., "dd")
comp_names %<>%
  map(str_replace, "_\\d", "") %>%
  map(unique)


#######################################################
#### Variant of purr::map #3 (at least 2 required) ####
#######################################################

# calculate alphas for the composites 
alphas <- comp_names %>%
  map(map_dbl, str_alpha, data = data1, full = FALSE) %>%
  flatten_dbl() 

# name the alpha composites
names(alphas) <- flatten_chr(comp_names)

#######################################################
#### Variant of purr::map #4 (at least 2 required) ####
#######################################################

# create composites
data_comp <- comp_names %>%
  map(map, str_composite, data1) %>%
  flatten_dfc()

# assign names to the created composites
names(data_comp) <- paste0(flatten_chr(comp_names), "_comp")

# combine the composites with the existing dataframe
data1 <- data1 %>%
  cbind(data_comp)

# clean up the environment
rm(list = setdiff(ls(), c("data1", "alphas", "costum_functions", custom_functions)))
```

# Intro

Sagacious intro text goes here.

# Method

## Participants and Procedure

A total of `r nrow(corr_data)` participants (68% female; age range: 18 to 34 years; *M* age = 19.61, *SD* age = 2.02) were recruited from the human subject pool at the University of Oregon. Data was collected over one academic quarter, and all participants were compensated with course credit necessary for meeting a course research requirement. Participants completed an online survey that included (1) a measure of the Dark Triad personality traits (i.e., Machiavellianism, narcissism, psychopathy), (2) questions assessing  participants' frequency of visiting eleven social media sites, (3) questions assessing the amount of time participants spend on those eleven social media sites, (4) a scale assessing the participants' addiction to social media, (5) a scale measuring participants' reasons for using the internet, and (6) two questions assessing participants' overall view of social media sites. The following analyses will only be focusing on the measure of the Dark Triad and the questions assessing frequency of use and amount of time spent on social media sites.

```{r tidy_data}


#################################################
#### Custom function 7 (at least 2 required) ####
#################################################

# create grouping variable function 
con_to_cat <- function(column) {
  cat_var <- case_when(column > quantile(column, .75, na.rm = TRUE) ~ "High",
                       column < quantile(column, .25, na.rm = TRUE) ~ "Low",
                       TRUE                                         ~ "Mid")
  cat_var <- factor(cat_var, levels = c("Low", "Mid", "High"))
  cat_var
}

# create variable specifying if an individual is..
# high, mid, or low in Machiavellianism
data1$mach_group <- con_to_cat(data1$dd_mach_comp)
# create variable specifying if an individual is..
# high, mid, or low in Narcissism
data1$narc_group <- con_to_cat(data1$dd_narc_comp)
# create variable specifying if an individual is..
# high, mid, or low in Psychopathy
data1$psyc_group <- con_to_cat(data1$dd_psyc_comp)

#selcting only variables I am interested in (dropping single items)
ash_data <- data1 %>%
  select(id, age, gender, race, sns:sns_perc_rating, contains("comp"),
         contains("group")) %>%
  filter(gender == "Male" | gender == "Female") %>%
  arrange(id)

# corr dataset is in wide format. I deleted data specific to each social media site and computed sum variables refelcting total time spend on social media 
corr_data <- ash_data %>% 
  spread(sns_perc_context, sns_perc_rating) %>%
  group_by(id) %>%
  mutate(mean_freq = mean(freq, na.rm = TRUE),
         sum_freq = sum(freq, na.rm = TRUE),
         sum_len = sum(len, na.rm = TRUE)) %>%
  select(id, gender, sum_freq, sum_len, self, society, 
         contains("comp"), contains("addict"), contains("group")) %>%
  unique()

# if we are interested in gender comparisons, we should probably exclude sns sites that don't have adaquate sample sizes (i.e., there are more than 25 females and 25 males)
# this data frame counts how many males and females use a given social media site
test <- data1 %>%
  filter(gender == "Male" | gender == "Female") %>%
  mutate(great_0 = if_else(freq > 1, 1, 0)) %>%
  group_by(gender, sns) %>%
  summarise(great_0_sum = sum(great_0, na.rm = TRUE))

# # dataset for gender specific analyses:
# genderxsns_data <- data1 %>%
#   select(id, age, gender, race, sns:sns_perc_rating, 
#          contains("comp"), contains("group")) %>%
#   filter(gender == "Male" | gender == "Female") %>%
#   filter(sns != "4chan" & # only 6 men and 6 women use 4chan
#          sns != "linkedin" & # only 14 men use linkedin
#          sns != "pinterest" & # only 4 men use pinterest
#          sns != "tumblr" & # only 4 men use tumblr
#          sns != "whatsapp") %>% # only 2 men use whatsapp
#   arrange(id)

# corr_data %>%
#   filter(gender == "Female") %>%
#   nrow() #102/149 females

# data1 %>%
#   select(id, age) %>%
#   unique() %>%
#   mutate(age = as.numeric(age)) %>%
#   summarize(m_age = mean(age, na.rm = TRUE),
#             sd_age = sd(age, na.rm = TRUE),
#             max_age = max(age, na.rm = TRUE),
#             min_age = min(age, na.rm = TRUE))

```

## Materials

# Results

```{r correlations}

corrs <- corr_data %>%
  select(id, sum_freq:int_addict_conflict_comp)

corrs <- cor(corrs, method = "pearson", use = "complete.obs")
corrs <- round(corrs, 2)

#insert heatmat????

```

```{r machxgender_plots}

#Examining whether social media use differ as a funciton of Machiavellianism
ash_data %>%
  filter(mach_group != "Mid",
         sns != "4chan" & 
         sns != "linkedin" & 
         sns != "pinterest" & 
         sns != "tumblr" & 
         sns != "whatsapp") %>% 
  group_by(sns, mach_group) %>%
  summarize(len_m  = mean(len, na.rm = TRUE),
            len_se = sundry::se(len)) %>%
  ggplot(aes(x = mach_group, y = len_m, fill = mach_group)) +
    geom_col(position = "dodge", alpha = 0.8) +
    geom_errorbar(aes(ymin = len_m - len_se, 
                      ymax = len_m + len_se),
                  position = "dodge",
                  colour = "grey30") +
    scale_fill_manual(values = c("#4A235A", "#D2B4DE")) +
    facet_wrap(~sns) +
    theme_bw(base_size = 14) +
    guides(fill=FALSE) +
    theme(axis.title = element_text(face = "bold"),
          strip.text = element_text(face = "bold", size = 14),
          legend.title = element_text(face = "bold")) +
    labs(y = "Average length spent on Social \nMedia Sites per Day (minutes)",
         x = "Machiavellianism")

#####################
#### Mach Models ####
#####################

mach_models <- list(len ~ dd_mach_comp + (1 | id),
                    len ~ dd_mach_comp*gender + (1 | id),
                    len ~ dd_mach_comp*sns + (1 | id),
                    len ~ dd_mach_comp*sns*gender + (1 | id))

mach_model_fits <- map(mach_models, ~lmer(.x, data = ash_data)) 

map(mach_model_fits, ~summary(.x))

map(mach_model_fits, ~anova(.x)) #not quite doing what I want.. I want model comparisons????

```

```{r narcxgender_plots}
#Examining whether social media use differ as a funciton of Narcissism (no gender)
ash_data %>%
  filter(narc_group != "Mid",
         sns != "4chan" & 
         sns != "linkedin" & 
         sns != "pinterest" & 
         sns != "tumblr" & 
         sns != "whatsapp") %>%
  group_by(sns, narc_group) %>% 
  summarize(len_m  = mean(len, na.rm = TRUE),
            len_se = sundry::se(len)) %>%
    ggplot(aes(x = narc_group, y = len_m, fill = narc_group)) +
    geom_col(position = "dodge", alpha = 0.8) +
    geom_errorbar(aes(ymin = len_m - len_se, 
                      ymax = len_m + len_se),
                  position = "dodge",
                  colour = "grey30") +
    scale_fill_manual(values = c("#17737B", "#5FCDD6")) +
    facet_wrap(~sns) +
    guides(fill=FALSE) +
    theme_bw(base_size = 14) +
    theme(axis.title = element_text(face = "bold"),
             strip.text = element_text(face = "bold", size = 14),
             legend.title = element_text(face = "bold")) +
    labs(y = "Average length spent on Social \nMedia Sites per Day (minutes)",
         x = "Narcissism")

###########################
#### Narcissism Models ####
###########################

narc_models <- list(len ~ dd_narc_comp + (1 | id),
                    len ~ dd_narc_comp*gender + (1 | id),
                    len ~ dd_narc_comp*sns + (1 | id),
                    len ~ dd_narc_comp*sns*gender + (1 | id))

narc_model_fits <- map(narc_models, ~lmer(.x, data = ash_data)) 

map(narc_model_fits, ~summary(.x))

map(narc_model_fits, ~anova(.x)) #not quite doing what I want.. I want model comparisons????

```

```{r psycxgender_plots}
#Examining whether social media use differ as a funciton of Psychopathy (no gender)
ash_data %>%
  filter(psyc_group != "Mid",
         sns != "4chan" & 
         sns != "linkedin" & 
         sns != "pinterest" & 
         sns != "tumblr" & 
         sns != "whatsapp") %>%
  group_by(sns, psyc_group) %>% 
  summarize(len_m  = mean(len, na.rm = TRUE),
            len_se = sundry::se(len)) %>%
  ggplot(aes(x = psyc_group, y = len_m, fill = psyc_group)) +
    geom_col(position = "dodge", alpha = 0.8) +
    geom_errorbar(aes(ymin = len_m - len_se, 
                      ymax = len_m + len_se),
                  position = "dodge",
                  colour = "grey30") +
    scale_fill_manual(values = c("#7B1740", "#D1769B")) +
    facet_wrap(~sns) +
    guides(fill=FALSE) +
    theme_bw(base_size = 14) +
    theme(axis.title = element_text(face = "bold"),
             strip.text = element_text(face = "bold", size = 14),
             legend.title = element_text(face = "bold")) +
    labs(y = "Average length spent on Social \nMedia Sites per Day (minutes)",
         x = "Psychopathy") 

############################
#### Psychopathy Models ####
############################

psyc_models <- list(len ~ dd_psyc_comp + (1 | id),
                    len ~ dd_psyc_comp*gender + (1 | id),
                    len ~ dd_psyc_comp*sns + (1 | id),
                    len ~ dd_psyc_comp*sns*gender + (1 | id))

psyc_model_fits <- map(psyc_models, ~lmer(.x, data = ash_data)) 

map(psyc_model_fits, ~summary(.x))

map(psyc_model_fits, ~anova(.x)) #not quite doing what I want.. I want model comparisons????

```


```{r gender_parallel_iteration}

# examining gender differences in minutes spent on social media each day
# by social media site
ash_data %>%
  group_by(gender, sns) %>%
  summarise(len_m = mean(len, na.rm = TRUE),
            len_se = se(len, na.rm = TRUE)) %>%
  ggplot(aes(x = sns, y = len_m, fill = gender)) + 
    geom_col(position = "dodge", alpha = 0.9) +
    scale_fill_manual(values = c("#633974", "#2A99A2"),
                      name = "Gender") +
    theme_bw(base_size = 14) +
    theme(axis.title = element_text(face = "bold"),
          strip.text = element_text(face = "bold", size = 14),
          legend.title = element_text(face = "bold")) +
    coord_flip() +
    labs(y = "Average Length Spent on Social Media Sites per Day (minutes)",
         x = "Social Media Site")

########################################################
### instance of parallel iteration # 1 (1 required) ####
## instance of purr::nest%>%mutate() # 1 (1 required) ##
########################################################

# lets examine potential gender effects on social media use..
# ...as a function of the dark triad traits

plot_data <- ash_data %>%
  filter(sns != "4chan" & 
         sns != "linkedin" & 
         sns != "pinterest" & 
         sns != "tumblr" & 
         sns != "whatsapp") %>%
  gather(key = dd_trait, value = standing, mach_group:psyc_group) %>%
  mutate(dd_trait = recode(dd_trait,
                        "mach_group" = "Machiavellianism",
                        "narc_group" = "Narcissism",
                        "psyc_group" = "Psychopathy"))
  
plot_data$standing <- factor(plot_data$standing, levels = c("Low", "Mid", "High"))

plot_data %<>%
  #filter(standing != "Mid") %>%
  spread(sns_perc_context, sns_perc_rating) %>%
  group_by(dd_trait, standing) %>%
  nest()

plot_data <- plot_data %>%
  mutate(plots = pmap(
    # create list of plot resources
    list(data_for_plot = plot_data$data,
         dd_trait = plot_data$dd_trait, 
         standing = plot_data$standing),
    # create plots
    function(data_for_plot, dd_trait, standing) {
      ggplot(data_for_plot, aes(x = gender, y = len, fill = gender)) +
        geom_col(position = "dodge") +
        scale_fill_manual(values = c("#633974", "#2A99A2")) +
        # apply theme minimal
        theme_bw(base_size = 12) +
        guides(fill=FALSE) +
        facet_wrap(~sns) +
        #scale_color_manual(values = c("#17737B", "#5FCDD6")) +
        theme(axis.title = element_text(face = "bold"),
              legend.title = element_text(face = "bold"),
              title = element_text(face = "bold"),
              strip.text = element_text(face = "bold"),
              legend.position = "bottom") +
        # set labels
        labs(title    = glue("Relation Between Time on Social Media and Gender for those {standing} in {dd_trait}"),
             y        = "Total Time Spent on Social Media \nSites per Day (Minutes)",
             x        = "Gender")
}))

plot_data$plots[[1]]
plot_data$plots[[2]]
plot_data$plots[[3]]
plot_data$plots[[4]]
plot_data$plots[[5]]
plot_data$plots[[6]]
plot_data$plots[[7]]
plot_data$plots[[8]]
plot_data$plots[[9]]
```

# Discussion

\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
