---
title             : "Clickbait Title with SEO Keywords"
shorttitle        : "Clickbait Title"

author: 
  - name          : "Cameron S. Kay"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Department of Psychology, 1227 University of Oregon, Eugene, OR 97403"
    email         : "ckay@uoregon.edu"
  - name          : "Ashley L. Miller"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "University of Oregon"

authornote: |
  Cameron Stuart Kay, Department of Psychology, University of Oregon; Ashley L. Miller, Department of Psychology, University of Oregon.

abstract: |
 Abstract goes herey
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["r-references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no

header-includes:
  - \raggedbottom
  - \setlength{\parskip}{0pt}

documentclass     : "apa6"
classoption       : "man, fleqn, noextraspace"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
# load required packaages
library("papaja") # for creating the apa journal article
library(tidyverse) # for purrr, dplyr, and ggplot2 functions
library(rio) # for easy imporrting of data
library(here) # for reproducible paths
library(magrittr) # for the compound assigiment pipe-operator
library(lme4) # for conducting linear mixed-effects models
library(lmerTest) # for calculating t-tests for linear mixed-effects models
library(psych) # for caculating cronbach's alpha

# import data as tibble and clean column names
data1 <- rio::import(here::here("data", "data_1.xlsx"), setclass = "tibble") %>%
  janitor::clean_names()

# turn off scientific notation
options(scipen = 999)
```

```{r data1_rename, include = FALSE}
# drop the display order columns and the custom demographic columns
data1 %<>%
  select(-contains("do"),
         -contains("text"))

# manualy rename the demographic columns
data1 %<>%
  rename(age          = q1_1,
         gender       = q1_2,
         race         = q1_4)


# create vectors of subscale names
dd_subs  <- c("mach", "narc", "psyc") # subscales for the dirty dozen scale

sns_subs <- c("facebook", # subscales for the frequency and length of sns use 
              "pinterest", 
              "instagram", 
              "linkedin", 
              "twitter", 
              "snapchat", 
              "youtube", 
              "whatsapp", 
              "reddit", 
              "4chan", 
              "tumblr")

con_subs <- c("society", # subscales for questions assessing benefit of sns
              "self")
 
mot_subs <- c("inform", # subscales for the motivations to use the internet 
              "interp", # scale
              "entert")
 
add_subs <- c("salience", # susbscales for the internet addiction scale
              "tolerance",
              "mood",
              "relapse",
              "withdraw",
              "conflict")

# create a tibble containing all the necessary information for renaming the 
# columns
data_rename <- tibble(
                      # the scale names
                      scale_names = c("dd", 
                                      "freq",
                                      "len",
                                      "sns_perc",
                                      "int_mot",
                                      "int_addict"),
                      # the scale subscales created above
                      sub_names   = list(dd_subs,
                                         sns_subs,
                                         sns_subs,
                                         con_subs,
                                         mot_subs,
                                         add_subs),
                      # the total length of the scales
                      scale_lens  = c(12, 11, 11, 2, 20, 18),
                      # the length of the subscales (only one value if all are 
                      # the same length)
                      sub_lens    = list(4, 1, 1, 1, c(8, 7, 5), 3))

# create a function for detecting columns names from a string
col_find <- function(pattern, data) {
  
  # ensure pattern is a character and the data is a dataframe
  if (!is.character(pattern)) {
    stop("Pattern must be of type character.")
  } else if (!is.data.frame(data)) {
    stop("Data must of type dataframe/tibble.")
  }
  
  # return column names that contain the pattern
  grepl(pattern, names(data))
}

# create a function for creating column names using the data_rename tibble
name_creator <- function(scale_name, sub_name, scale_len, sub_len) {
  
  # calculate the subscale length if no subscale length provided
  if (missing(sub_len)) {
    sub_len <- scale_len / length(sub_name)
  }
  
  # create a vector of subscale names to match length of the scale. `times` has 
  # to be used instead of `each` when subscales of different lengths are 
  # specified
  if (length(sub_len) == 1) {
    sub_vector <- rep(sub_name, each = sub_len)
  } else {
    sub_vector <- rep(sub_name, times = sub_len) 
  }

  # combine the scale names with the sub_scale names
  var_names <- paste(scale_name, sub_vector, sep = "_")
  
  # if length of the subscale is not equal to one, add an item identifier to the
  # column names (this segment, in particular, should be refactored)
  if (any(sub_len != 1)) {
    # get a sequence from 1 the length of a subscale for each subscale
    item_nums <- flatten_dbl(map(sub_len, seq_len))
    # repeat the sequence the number of subscales there are
    item_nums <- rep(item_nums, times = scale_len / sum(sub_len))
    # combine the variable names with the item numbers
    var_names <- paste(var_names, item_nums, sep = "_")
  }
  
  # return scale_sub
  var_names
  
}

# iterate through the data_rename tibble and create a list of column names
col_names <- pmap(list(data_rename$scale_names,
                       data_rename$sub_names,
                       data_rename$scale_lens,
                       data_rename$sub_lens),
                  ~name_creator(..1, ..2, ..3, ..4)
)

# assign created column names to data1
names(data1)[col_find("q7", data1)] <- unlist(col_names)

# remove uneeded variables
rm(list = setdiff(ls(), c("data1", "col_names", "col_find")))
```

```{r data1_convert_to_long}
# add an id column to the data
data1 %<>%
  mutate(id = 1:n()) %>%
  select(id, everything())

# transform the data to long format with respect the the frequency of sns use 
# and the length of sns use
data1 %<>%
  # over gather all frequency and length columns
  gather("key", "value", freq_facebook:len_tumblr) %>%
  # separate the key columns into a column specifying freq/length and a column
  # specifying the social media site
  separate(key, into = c("variable", "sns"), sep = "_") %>%
  # spread the frequency and length column into two separate columns
  spread(variable, value)

# transform the data to long format with respect to perception of sns
data1 %<>%
  # gather the two columns (i.e., benefit of sns to the self and benefit of sns
  # to society)
  gather("sns_perc_context", "sns_perc_rating", starts_with("sns_perc")) %>%
  # drop all text before "self" or "society
  mutate(sns_perc_context = gsub(".*_", "", sns_perc_context))

```

```{r data1_parse_length}
# identify the units responses were given in (even though I requested answers in 
# minutes)
data1 %<>%
  mutate(len_unit  = case_when(grepl("(hour|hr)", len) ~ 60,
                               TRUE                    ~ 1))

# create a function for calculating the mean of time responses given as a 
# character ranges. Example: "like 3-5 hours a day" would become "4"
range_mean <- function(x) {
  # attempt to find a mean for only those with a hyphen in the response
  if (grepl("-", x)) {
    # extract the range from the response
    x <- str_extract(x, "\\d*-\\d*")
    # split the string around the dash
    x <- strsplit(x, "-")[[1]]
    # convert the string to numeric and calculate the mean
    x <- mean(as.numeric(x))
    # maintaining the original type, convert the result back to a character
    as.character(x)
  } else {
    # if no hyphen, return x
    x
  }
}

# replace all range responses with the means of those ranges
data1$len <- map_chr(data1$len, range_mean)

# parse the numbers
data1 %<>%
  mutate(# replace written numbers with arabic numerals
         len = case_when(len == "ten"                  ~ "10",
                         len == "3o"                   ~ "30",
                         len == "sixty"                ~ "60",
                         len == "eighty"               ~ "80",
                         grepl("(zero|no|never)", len) ~ "0",
                         TRUE                          ~ len),
         # parse the numbers
         len = parse_number(len),
         # calculate the length in minutes
         len = len * len_unit) %>%
         # drop the unit column
         select(-len_unit)
```

```{r data1_format}
# factorize and label factors
data1 %<>%
  mutate(# factorize gender and apply labels
        gender           = factor(gender, labels = c("Male",
                                                     "Female",
                                                     "Non-binary",
                                                     "Prefer not to say",
                                                     "Other")),
        # factorize race and apply labels
        race             = factor(race, labels   = c("American Indian or Alaska Native",
                                                     "Asian",
                                                     "Black or African American",
                                                     "Native Hawaiian or Other Pacific Islander",
                                                     "Caucasian",
                                                     "Hispanic, Latinx, or Spanish Origin",
                                                     "Middle Eastern or North African",
                                                     "I prefer not to answer",
                                                     "Some other ethnicity or origin")),
        # factorize social media site
        sns              = factor(sns),
        # factorize context
        sns_perc_context = factor(sns_perc_context),
        # numerize frequency
        freq             = as.numeric(freq))

```


```{r data1_composites}
# drop column names not to be made into composites
comp_names <- col_names[-2:-4]

# drop item identifiers to create the composite names and retain only unique names
comp_names %<>%
  map(str_replace, "_\\d", "") %>%
  map(unique)

# create alphaizer function
str_alpha <- function(col, data) {
  # find names of columns that match the string
  cols_found  <- col_find(col, data)
  # extract only those columns from the data 
  data <- data[, cols_found]
  # calculate and extract the alpha value
  alpha(data)[["total"]][["raw_alpha"]]
}

# calculate alphas for the composite
comp_alphas <- comp_names %>%
  map(map_dbl, str_alpha, data1) %>%
  flatten_dbl() 

# name the alpha composites
comp_alphas <- flatten_chr(comp_names)


```

Sagacious intro text goes here.

# Method

## Participants

## Material and procedure

# Results

```{r trash_plots}
# plot for fun
data1 %>%
  filter(gender == "Male" | gender == "Female") %>%
  group_by(gender, sns) %>%
  summarise(len_m = mean(len, na.rm = TRUE)) %>%
  ggplot(aes(x = sns, y = len_m, fill = gender)) + 
    geom_col(position = "dodge") +
    scale_fill_manual(values = c("steelblue3", "darkorchid3")) +
    theme_bw() +
    coord_flip() +
    labs(y = "Average length spent on Social Media Sites per Day (minutes)",
         x = "Social Media Site")

data1 %>%
  filter(gender == "Male" | gender == "Female") %>%
  group_by(gender, sns) %>%
  summarise(freq_m = mean(freq, na.rm = TRUE)) %>%
  ggplot(aes(x = sns, y = freq_m, fill = gender)) + 
    geom_col(position = "dodge") +
    scale_fill_manual(values = c("steelblue3", "darkorchid3")) +
    theme_bw() +
    coord_flip() +
    labs(y = "Average frequency of using the social media sites",
         x = "Social Media Site") +
    scale_y_continuous(labels = c("Rarely", "Monthly", "Weekly", 
                                  "Daily", "Multiple times of day"))
  

```

# Discussion

\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
