---
title             : "Clickbait Title with SEO Keywords"
shorttitle        : "Clickbait Title"

author: 
  - name          : "Cameron S. Kay"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "Department of Psychology, 1227 University of Oregon, Eugene, OR 97403"
    email         : "ckay@uoregon.edu"
  - name          : "Ashley L. Miller"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "University of Oregon"

authornote: |
  Cameron Stuart Kay, Department of Psychology, University of Oregon; Ashley L. Miller, Department of Psychology, University of Oregon.

abstract: |
 Abstract goes herey
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["r-references.bib"]

floatsintext      : no
figurelist        : no
tablelist         : no
footnotelist      : no
linenumbers       : no
mask              : no
draft             : no

header-includes:
  - \raggedbottom
  - \setlength{\parskip}{0pt}

documentclass     : "apa6"
classoption       : "man, fleqn, noextraspace"
output            : papaja::apa6_pdf
---

```{r setup, include = FALSE}
# load required packaages
library(sundry)
library("papaja") # for creating the apa journal article
library(tidyverse) # for purrr, dplyr, and ggplot2 functions
library(rio) # for easy imporrting of data
library(here) # for reproducible paths
library(magrittr) # for the compound assigiment pipe-operator
library(lme4) # for conducting linear mixed-effects models
library(lmerTest) # for calculating t-tests for linear mixed-effects models
library(psych) # for caculating cronbach's alpha

# import data as tibble and clean column names
data1 <- rio::import(here::here("data", "data_1.xlsx"), setclass = "tibble") %>%
  janitor::clean_names()

# turn off scientific notation
options(scipen = 999)
```

```{r data1_rename, include = FALSE}
# drop the display order columns and the custom demographic columns
data1 %<>%
  select(-contains("do"),
         -contains("text"))

# manualy rename the demographic columns
data1 %<>%
  rename(age          = q1_1,
         gender       = q1_2,
         race         = q1_4)


# create vectors of subscale names
dd_subs  <- c("mach", "narc", "psyc") # subscales for the dirty dozen scale

sns_subs <- c("facebook", # subscales for the frequency and length of sns use 
              "pinterest", 
              "instagram", 
              "linkedin", 
              "twitter", 
              "snapchat", 
              "youtube", 
              "whatsapp", 
              "reddit", 
              "4chan", 
              "tumblr")

con_subs <- c("society", # subscales for questions assessing benefit of sns
              "self")
 
mot_subs <- c("inform", # subscales for the motivations to use the internet 
              "interp", # scale
              "entert")
 
add_subs <- c("salience", # susbscales for the internet addiction scale
              "tolerance",
              "mood",
              "relapse",
              "withdraw",
              "conflict")

# create a tibble containing all the necessary information for renaming the 
# columns
data_rename <- tibble(
                      # the scale names
                      scale_names = c("dd", 
                                      "freq",
                                      "len",
                                      "sns_perc",
                                      "int_mot",
                                      "int_addict"),
                      # the scale subscales created above
                      sub_names   = list(dd_subs,
                                         sns_subs,
                                         sns_subs,
                                         con_subs,
                                         mot_subs,
                                         add_subs),
                      # the total length of the scales
                      scale_lens  = c(12, 11, 11, 2, 20, 18),
                      # the length of the subscales (only one value if all are 
                      # the same length)
                      sub_lens    = list(4, 1, 1, 1, c(8, 7, 5), 3))


#################################################
#### Custom function 1 (at least 2 required) ####
#################################################

# create a function for detecting columns names from a string
col_find <- function(pattern, data) {
  
  # ensure pattern is a character and the data is a dataframe
  if (!is.character(pattern)) {
    stop("Pattern must be of type character.")
  } else if (!is.data.frame(data)) {
    stop("Data must of type dataframe/tibble.")
  }
  
  # return column names that contain the pattern
  grepl(pattern, names(data))
}

#################################################
#### Custom function 2 (at least 2 required) ####
#################################################

# create a function for creating column names using the data_rename tibble
name_creator <- function(scale_name, sub_name, scale_len, sub_len) {
  
  # calculate the subscale length if no subscale length provided
  if (missing(sub_len)) {
    sub_len <- scale_len / length(sub_name)
  }
  
  # create a vector of subscale names to match length of the scale. `times` has 
  # to be used instead of `each` when subscales of different lengths are 
  # specified
  if (length(sub_len) == 1) {
    sub_vector <- rep(sub_name, each = sub_len)
  } else {
    sub_vector <- rep(sub_name, times = sub_len) 
  }

  # combine the scale names with the sub_scale names
  var_names <- paste(scale_name, sub_vector, sep = "_")
  
  # if length of the subscale is not equal to one, add an item identifier to the
  # column names (this segment, in particular, should be refactored)
  if (any(sub_len != 1)) {
    # get a sequence from 1 the length of a subscale for each subscale
    item_nums <- flatten_dbl(map(sub_len, seq_len))
    # repeat the sequence the number of subscales there are
    item_nums <- rep(item_nums, times = scale_len / sum(sub_len))
    # combine the variable names with the item numbers
    var_names <- paste(var_names, item_nums, sep = "_")
  }
  
  # return scale_sub
  var_names
  
}

# iterate through the data_rename tibble and create a list of column names
col_names <- pmap(list(data_rename$scale_names,
                       data_rename$sub_names,
                       data_rename$scale_lens,
                       data_rename$sub_lens),
                  ~name_creator(..1, ..2, ..3, ..4)
)

# assign created column names to data1
names(data1)[col_find("q7", data1)] <- unlist(col_names)

# remove uneeded variables
rm(list = setdiff(ls(), c("data1", "col_names", "col_find")))
```

```{r data1_convert_to_long, include = FALSE}
# add an id column to the data
data1 %<>%
  mutate(id = 1:n()) %>%
  select(id, everything())

# transform the data to long format with respect the the frequency of sns use 
# and the length of sns use
data1 %<>%
  # over gather all frequency and length columns
  gather("key", "value", freq_facebook:len_tumblr) %>%
  # separate the key columns into a column specifying freq/length and a column
  # specifying the social media site
  separate(key, into = c("variable", "sns"), sep = "_") %>%
  # spread the frequency and length column into two separate columns
  spread(variable, value)

# transform the data to long format with respect to perception of sns
data1 %<>%
  # gather the two columns (i.e., benefit of sns to the self and benefit of sns
  # to society)
  gather("sns_perc_context", "sns_perc_rating", starts_with("sns_perc")) %>%
  # drop all text before "self" or "society
  mutate(sns_perc_context = gsub(".*_", "", sns_perc_context))

```

```{r data1_parse_length, include = FALSE}
# identify the units responses were given in (even though I requested answers in 
# minutes)
data1 %<>%
  mutate(len_unit  = case_when(grepl("(hour|hr)", len) ~ 60,
                               TRUE                    ~ 1))

#################################################
#### Custom function 3 (at least 2 required) ####
#################################################

# create a function for calculating the mean of time responses given as a 
# character ranges. Example: "like 3-5 hours a day" would become "4"
range_mean <- function(x) {
  # attempt to find a mean for only those with a hyphen in the response
  if (grepl("-", x)) {
    # extract the range from the response
    x <- str_extract(x, "\\d*-\\d*")
    # split the string around the dash
    x <- strsplit(x, "-")[[1]]
    # convert the string to numeric and calculate the mean
    x <- mean(as.numeric(x))
    # maintaining the original type, convert the result back to a character
    as.character(x)
  } else {
    # if no hyphen, return x
    x
  }
}


#######################################################
#### Variant of purr::map #1 (at least 2 required) ####
#######################################################

# replace all range responses with the means of those ranges
data1$len <- map_chr(data1$len, range_mean)

# parse the numbers
data1 %<>%
  mutate(# replace written numbers with arabic numerals
         len = case_when(len == "ten"                  ~ "10",
                         len == "3o"                   ~ "30",
                         len == "sixty"                ~ "60",
                         len == "eighty"               ~ "80",
                         grepl("(zero|no|never)", len) ~ "0",
                         TRUE                          ~ len),
         # parse the numbers
         len = parse_number(len),
         # calculate the length in minutes
         len = len * len_unit) %>%
         # drop the unit column
         select(-len_unit)
```

```{r data1_format, include = FALSE}
# factorize and label factors
data1 %<>%
  mutate(# factorize gender and apply labels
        gender           = factor(gender, labels = c("Male",
                                                     "Female",
                                                     "Non-binary",
                                                     "Prefer not to say",
                                                     "Other")),
        # factorize race and apply labels
        race             = factor(race, labels   = c("American Indian or Alaska Native",
                                                     "Asian",
                                                     "Black or African American",
                                                     "Native Hawaiian or Other Pacific Islander",
                                                     "Caucasian",
                                                     "Hispanic, Latinx, or Spanish Origin",
                                                     "Middle Eastern or North African",
                                                     "I prefer not to answer",
                                                     "Some other ethnicity or origin")),
        # factorize social media site
        sns              = factor(sns),
        # factorize context
        sns_perc_context = factor(sns_perc_context),
        # numerize frequency
        freq             = as.numeric(freq))

```

```{r data1_composites, include = FALSE}
# drop column names not to be made into composites
comp_names <- col_names[-2:-4]


#######################################################
#### Variant of purr::map #2 (at least 2 required) ####
#######################################################

# drop item identifiers to create the composite names; retain only unique names
comp_names %<>%
  map(str_replace, "_\\d", "") %>%
  map(unique)

#################################################
#### Custom function 4 (at least 2 required) ####
#################################################

# create a function for calculating alpha given a string pattern
str_alpha <- function(pattern, data) {
  # find names of columns that match the string
  cols_found  <- col_find(pattern, data)
  # extract only those columns from the data 
  data <- data[, cols_found]
  # calculate and extract the alpha value
  alpha(data)[["total"]][["raw_alpha"]]
}

#######################################################
#### Variant of purr::map #3 (at least 2 required) ####
#######################################################

# calculate alphas for the composites
alphas <- comp_names %>%
  map(map_dbl, str_alpha, data1) %>%
  flatten_dbl() 

# name the alpha composites
names(alphas) <- flatten_chr(comp_names)

#################################################
#### Custom function 5 (at least 2 required) ####
#################################################

# create the str_message function for double-checking one's work
str_message <- function(data) {
  names_len <- length(names(data))
  if (names_len <= 4) {
    col_names <- paste(names(data), collapse = ", ")
  } else {
    col_names <- paste0(paste(names(data)[1:3], collapse = ", "), ", and ", names_len - 3, " more")
  }
  message(paste0("Row means were calculated using ", 
                ncol(data), 
                " columns: ",
                col_names,
                "."))
}

#################################################
#### Custom function 6 (at least 2 required) ####
#################################################

# create a function for calculating rowmeans given a string pattern
str_means <- function(pattern, data) {
  # find names of columns that match the string
  cols_found  <- col_find(pattern, data)
  # extract only those columns from the data 
  data <- data[, cols_found]
  # message user how the composites were created
  str_message(data)
  # calculate row means
  rowMeans(data)
}

#######################################################
#### Variant of purr::map #4 (at least 2 required) ####
#######################################################

# create composites
data_comp <- comp_names %>%
  map(map, str_means, data1) %>%
  flatten_dfc()

# assign names to the created composites
names(data_comp) <- paste0(flatten_chr(comp_names), "_comp")

# combine the composites with the existing dataframe
data1 <- data1 %>%
  cbind(data_comp)

# drop unneeded, single item columns (ACTUALLY, we'll need these for checking SDs)
#data1 %<>%
#  select(-matches("\\d$"))

# clean up the environment
rm(list = setdiff(ls(), c("data1", "alphas", "col_find")))
```

```{r tidy_data}


#################################################
#### Custom function 7 (at least 2 required) ####
#################################################

# create grouping variable function 
con_to_cat <- function(column) {
  cat_var <- case_when(column > quantile(column, .75, na.rm = TRUE) ~ "High",
                       column < quantile(column, .25, na.rm = TRUE) ~ "Low",
                       TRUE                                         ~ "Mid")
  cat_var <- factor(cat_var, levels = c("Low", "Mid", "High"))
  cat_var
}

# create variable specifying if an individual is..
# high, mid, or low in Machiavellianism
data1$mach_group <- con_to_cat(data1$dd_mach_comp)
# create variable specifying if an individual is..
# high, mid, or low in Narcissism
data1$narc_group <- con_to_cat(data1$dd_narc_comp)
# create variable specifying if an individual is..
# high, mid, or low in Psychopathy
data1$psyc_group <- con_to_cat(data1$dd_psyc_comp)

#selcting only variables I am interested in (dropping single items)
ash_data <- data1 %>%
  select(id, age, gender, race, sns:sns_perc_rating, contains("comp"),
         contains("group")) %>%
  filter(gender == "Male" | gender == "Female") %>%
  arrange(id)

# corr dataset is in wide format. I deleted data specific to each social media site and computed sum variables refelcting total time spend on social media 
corr_data <- ash_data %>% 
  spread(sns_perc_context, sns_perc_rating) %>%
  group_by(id) %>%
  mutate(mean_freq = mean(freq, na.rm = TRUE),
         sum_freq = sum(freq, na.rm = TRUE),
         sum_len = sum(len, na.rm = TRUE)) %>%
  select(id, gender, sum_freq, sum_len, self, society, 
         contains("comp"), contains("addict"), contains("group")) %>%
  unique()

# if we are interested in gender comparisons, we should probably exclude sns sites that don't have adaquate sample sizes (i.e., there are more than 25 females and 25 males)
# this data frame counts how many males and females use a given social media site
test <- data1 %>%
  filter(gender == "Male" | gender == "Female") %>%
  mutate(great_0 = if_else(freq > 1, 1, 0)) %>%
  group_by(gender, sns) %>%
  summarise(great_0_sum = sum(great_0, na.rm = TRUE))

# # dataset for gender specific analyses:
# genderxsns_data <- data1 %>%
#   select(id, age, gender, race, sns:sns_perc_rating, 
#          contains("comp"), contains("group")) %>%
#   filter(gender == "Male" | gender == "Female") %>%
#   filter(sns != "4chan" & # only 6 men and 6 women use 4chan
#          sns != "linkedin" & # only 14 men use linkedin
#          sns != "pinterest" & # only 4 men use pinterest
#          sns != "tumblr" & # only 4 men use tumblr
#          sns != "whatsapp") %>% # only 2 men use whatsapp
#   arrange(id)

# corr_data %>%
#   filter(gender == "Female") %>%
#   nrow() #102/149 females

# data1 %>%
#   select(id, age) %>%
#   unique() %>%
#   mutate(age = as.numeric(age)) %>%
#   summarize(m_age = mean(age, na.rm = TRUE),
#             sd_age = sd(age, na.rm = TRUE),
#             max_age = max(age, na.rm = TRUE),
#             min_age = min(age, na.rm = TRUE))

```

# Intro

Sagacious intro text goes here.

# Method

## Participants and Procedure

A total of `r nrow(corr_data)` participants (68% female; age range: 18 to 34 years; *M* age = 19.61, *SD* age = 2.02) were recruited from the human subject pool at the University of Oregon. Data was collected over one academic quarter, and all participants were compensated with course credit necessary for meeting a course research requirement. Participants completed an online survey that included (1) a measure of the Dark Triad personality traits (i.e., Machiavellianism, narcissism, psychopathy), (2) questions assessing  participants' frequency of visiting eleven social media sites, (3) questions assessing the amount of time participants spend on those eleven social media sites, (4) a scale assessing the participants' addiction to social media, (5) a scale measuring participants' reasons for using the internet, and (6) two questions assessing participants' overall view of social media sites. The following analyses will only be focusing on the measure of the Dark Triad and the questions assessing frequency of use and amount of time spent on social media sites.

## Materials

# Results

```{r gender_plots}
# examining gender differences in minutes spent on social media each day
#faceted by social media site
ash_data %>%
  group_by(gender, sns) %>%
  summarise(len_m = mean(len, na.rm = TRUE),
            len_se = se(len, na.rm = TRUE)) %>%
  ggplot(aes(x = sns, y = len_m, fill = gender)) + 
    geom_col(position = "dodge", alpha = 0.7) +
    scale_fill_manual(values = c("#633974", "#2A99A2"),
                      name = "Gender") +
    theme_bw(base_size = 14) +
    theme(axis.title = element_text(face = "bold"),
          strip.text = element_text(face = "bold", size = 14),
          legend.title = element_text(face = "bold")) +
    coord_flip() +
    labs(y = "Average Length Spent on Social Media Sites per Day (minutes)",
         x = "Social Media Site")
```

```{r correlations}

corrs <- corr_data %>%
  select(id, sum_freq:int_addict_conflict_comp)

corrs <- cor(corrs, method = "pearson", use = "complete.obs")
corrs <- round(corrs, 2)

#insert heatmat????

```

```{r machxgender_plots}

#Examining whether gender effects differ as a funciton of Machiavellianism
ash_data %>%
  filter(mach_group != "Mid") %>%
  filter(sns != "4chan" & # only 6 men and 6 women use 4chan
         sns != "linkedin" & # only 14 men use linkedin
         sns != "pinterest" & # only 4 men use pinterest
         sns != "tumblr" & # only 4 men use tumblr
         sns != "whatsapp") %>% # only 2 men use whatsapp
  group_by(sns, gender, mach_group) %>% 
  summarize(len_m  = mean(len, na.rm = TRUE),
            len_se = sundry::se(len)) %>%
  ggplot(aes(x = mach_group, y = len_m, fill = gender)) +
    geom_col(position = "dodge", alpha = 0.8) +
    geom_errorbar(aes(ymin = len_m - len_se, 
                      ymax = len_m + len_se),
                  position = "dodge",
                  colour = "grey30") +
    scale_fill_manual(values = c("#4A235A", "#D2B4DE"),
                         name  = "Gender",
                         breaks = c("Male", "Female"),
                         labels = c("Male", "Female")) +
    facet_wrap(~sns) +
    theme_bw(base_size = 14) +
    theme(axis.title = element_text(face = "bold"),
             strip.text = element_text(face = "bold", size = 14),
             legend.title = element_text(face = "bold")) +
    labs(y = "Average length spent on Social \nMedia Sites per Day (minutes)",
         x = "Machiavellianism",
         colour = "Gender") 

#Examining whether social media use differ as a funciton of Machiavellianism
ash_data %>%
  filter(mach_group != "Mid",
         sns != "4chan" & 
         sns != "linkedin" & 
         sns != "pinterest" & 
         sns != "tumblr" & 
         sns != "whatsapp") %>% 
  group_by(sns, mach_group) %>%
  summarize(len_m  = mean(len, na.rm = TRUE),
            len_se = sundry::se(len)) %>%
  ggplot(aes(x = mach_group, y = len_m, fill = mach_group)) +
    geom_col(position = "dodge", alpha = 0.8) +
    geom_errorbar(aes(ymin = len_m - len_se, 
                      ymax = len_m + len_se),
                  position = "dodge",
                  colour = "grey30") +
    scale_fill_manual(values = c("#4A235A", "#D2B4DE")) +
    facet_wrap(~sns) +
    theme_bw(base_size = 14) +
    guides(fill=FALSE) +
    theme(axis.title = element_text(face = "bold"),
          strip.text = element_text(face = "bold", size = 14),
          legend.title = element_text(face = "bold")) +
    labs(y = "Average length spent on Social \nMedia Sites per Day (minutes)",
         x = "Machiavellianism")

#####################
#### Mach Models ####
#####################

mach_models <- list(len ~ dd_mach_comp + (1 | id),
                    len ~ dd_mach_comp*gender + (1 | id),
                    len ~ dd_mach_comp*sns + (1 | id),
                    len ~ dd_mach_comp*sns*gender + (1 | id))

mach_model_fits <- map(mach_models, ~lmer(.x, data = ash_data)) 

map(mach_model_fits, ~summary(.x))

map(mach_model_fits, ~anova(.x)) #not quite doing what I want.. I want model comparisons????

```

```{r narcxgender_plots}
#Examining whether gender effects on social media use differ as a funciton of Narcissism
ash_data %>%
  filter(narc_group != "Mid",
         sns != "4chan" & 
         sns != "linkedin" & 
         sns != "pinterest" & 
         sns != "tumblr" & 
         sns != "whatsapp") %>%
  group_by(sns, gender, narc_group) %>% 
  summarize(len_m  = mean(len, na.rm = TRUE),
            len_se = sundry::se(len)) %>%
    ggplot(aes(x = narc_group, y = len_m, fill = gender)) +
    geom_col(position = "dodge", alpha = 0.8) +
    geom_errorbar(aes(ymin = len_m - len_se, 
                      ymax = len_m + len_se),
                  position = "dodge",
                  colour = "grey30") +
    scale_fill_manual(values = c("#17737B", "#5FCDD6"),
                         name  = "Gender",
                         breaks = c("Male", "Female"),
                         labels = c("Male", "Female")) +
    facet_wrap(~sns) +
    theme_bw(base_size = 14) +
    theme(axis.title = element_text(face = "bold"),
             strip.text = element_text(face = "bold", size = 14),
             legend.title = element_text(face = "bold")) +
    labs(y = "Average length spent on Social \nMedia Sites per Day (minutes)",
         x = "Narcissism",
         colour = "Gender") 

#Examining whether social media use differ as a funciton of Narcissism (no gender)
ash_data %>%
  filter(narc_group != "Mid",
         sns != "4chan" & 
         sns != "linkedin" & 
         sns != "pinterest" & 
         sns != "tumblr" & 
         sns != "whatsapp") %>%
  group_by(sns, narc_group) %>% 
  summarize(len_m  = mean(len, na.rm = TRUE),
            len_se = sundry::se(len)) %>%
    ggplot(aes(x = narc_group, y = len_m, fill = narc_group)) +
    geom_col(position = "dodge", alpha = 0.8) +
    geom_errorbar(aes(ymin = len_m - len_se, 
                      ymax = len_m + len_se),
                  position = "dodge",
                  colour = "grey30") +
    scale_fill_manual(values = c("#17737B", "#5FCDD6")) +
    facet_wrap(~sns) +
    guides(fill=FALSE) +
    theme_bw(base_size = 14) +
    theme(axis.title = element_text(face = "bold"),
             strip.text = element_text(face = "bold", size = 14),
             legend.title = element_text(face = "bold")) +
    labs(y = "Average length spent on Social \nMedia Sites per Day (minutes)",
         x = "Narcissism")

###########################
#### Narcissism Models ####
###########################

narc_models <- list(len ~ dd_narc_comp + (1 | id),
                    len ~ dd_narc_comp*gender + (1 | id),
                    len ~ dd_narc_comp*sns + (1 | id),
                    len ~ dd_narc_comp*sns*gender + (1 | id))

narc_model_fits <- map(narc_models, ~lmer(.x, data = ash_data)) 

map(narc_model_fits, ~summary(.x))

map(narc_model_fits, ~anova(.x)) #not quite doing what I want.. I want model comparisons????

```

```{r psycxgender_plots}
#Examining whether gender effects on social media use differ as a funciton of Psychopathy
ash_data %>%
  filter(psyc_group != "Mid",
         sns != "4chan" & 
         sns != "linkedin" & 
         sns != "pinterest" & 
         sns != "tumblr" & 
         sns != "whatsapp") %>%
  group_by(sns, gender, psyc_group) %>% 
  summarize(len_m  = mean(len, na.rm = TRUE),
            len_se = sundry::se(len)) %>%
  ggplot(aes(x = psyc_group, y = len_m, fill = gender)) +
    geom_col(position = "dodge", alpha = 0.8) +
    geom_errorbar(aes(ymin = len_m - len_se, 
                      ymax = len_m + len_se),
                  position = "dodge",
                  colour = "grey30") +
    scale_fill_manual(values = c("#7B1740", "#D1769B"),
                      name  = "Gender",
                      breaks = c("Male", "Female"),
                      labels = c("Male", "Female")) +
    facet_wrap(~sns) +
    theme_bw(base_size = 14) +
    theme(axis.title = element_text(face = "bold"),
             strip.text = element_text(face = "bold", size = 14),
             legend.title = element_text(face = "bold")) +
    labs(y = "Average length spent on Social \nMedia Sites per Day (minutes)",
         x = "Psychopathy",
         colour = "Gender") 

#Examining whether social media use differ as a funciton of Psychopathy (no gender)
ash_data %>%
  filter(psyc_group != "Mid",
         sns != "4chan" & 
         sns != "linkedin" & 
         sns != "pinterest" & 
         sns != "tumblr" & 
         sns != "whatsapp") %>%
  group_by(sns, psyc_group) %>% 
  summarize(len_m  = mean(len, na.rm = TRUE),
            len_se = sundry::se(len)) %>%
  ggplot(aes(x = psyc_group, y = len_m, fill = psyc_group)) +
    geom_col(position = "dodge", alpha = 0.8) +
    geom_errorbar(aes(ymin = len_m - len_se, 
                      ymax = len_m + len_se),
                  position = "dodge",
                  colour = "grey30") +
    scale_fill_manual(values = c("#7B1740", "#D1769B")) +
    facet_wrap(~sns) +
    guides(fill=FALSE) +
    theme_bw(base_size = 14) +
    theme(axis.title = element_text(face = "bold"),
             strip.text = element_text(face = "bold", size = 14),
             legend.title = element_text(face = "bold")) +
    labs(y = "Average length spent on Social \nMedia Sites per Day (minutes)",
         x = "Psychopathy") 

############################
#### Psychopathy Models ####
############################

psyc_models <- list(len ~ dd_psyc_comp + (1 | id),
                    len ~ dd_psyc_comp*gender + (1 | id),
                    len ~ dd_psyc_comp*sns + (1 | id),
                    len ~ dd_psyc_comp*sns*gender + (1 | id))

psyc_model_fits <- map(psyc_models, ~lmer(.x, data = ash_data)) 

map(psyc_model_fits, ~summary(.x))

map(psyc_model_fits, ~anova(.x)) #not quite doing what I want.. I want model comparisons????

```

```{r parallel iteration}

########################################################
### instance of parallel iteration # 1 (1 required) ####
## instance of purr::nest%>%mutate() # 1 (1 required) ##
########################################################

plot_data <- ash_data %>%
  # filter(sns != "4chan" & 
  #        sns != "linkedin" & 
  #        sns != "pinterest" & 
  #        sns != "tumblr" & 
  #        sns != "whatsapp") %>%
  spread(sns_perc_context, sns_perc_rating) %>%
  group_by(sns) %>%
  nest()

library(glue)

plot_data <- test %>%
  mutate(plots = pmap(
    # create list of plot resources
    list(data_for_plot = plot_data$data,
         sns = plot_data$sns),
    # create plots
    function(data_for_plot, sns) {
      ggplot(data_for_plot, aes(x = int_addict_salience_comp, y = len,
                                group = gender, colour = gender)) +
        geom_smooth(method = "lm", 
                    se = FALSE,
                    size = 2) +
        scale_colour_manual(values = c("#633974", "#2A99A2"),
                            name = "Gender") +
        # apply theme minimal
        theme_bw(base_size = 12) +
        #scale_color_manual(values = c("#17737B", "#5FCDD6")) +
        theme(axis.title = element_text(face = "bold"),
              strip.text = element_text(face = "bold", size = 14),
              legend.title = element_text(face = "bold")) +
        # set labels
        labs(title    = glue("Relation between time on social media \nand addictive salience: {sns}"),
             y        = "Total Time Spent on Social \nMedia Sites per Day (minutes)",
             x        = "Social Media Addiction Salience")
}))

plot_data$plots[[1]]
plot_data$plots[[2]]
plot_data$plots[[3]]
plot_data$plots[[4]]
plot_data$plots[[5]]
plot_data$plots[[6]]
plot_data$plots[[7]]
plot_data$plots[[8]]
plot_data$plots[[9]]
plot_data$plots[[10]]
plot_data$plots[[11]]

```


# Discussion

\newpage

# References
```{r create_r-references}
r_refs(file = "r-references.bib")
```

\begingroup
\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}

<div id = "refs"></div>
\endgroup
